# pyspark

Problem 1: Write a pyspark program to analyze website log data to understand user access patterns and identify the most requested pages.

Problem 2: Write a pyspark program to analyze the movie data, identifying the genre with the highest average rating among movies rated above 8.

Problem 3: Write a pyspark application to demonstrates the usage of logging, tqdm, and PySpark functionalities for processing a sample DataFrame, showcasing progress tracking and informative logging during data transformations.

Problem 4: Write a pyspark application to clean and transform in-memory data containing missing values and inconsistencies before creating a PySpark DataFrame.

Problem 5: Write a pyspark application to add an "index-like" column to a PySpark DataFrame.

Problem 6: Develope a pyspark application to calculate the month-wise cumulative revenue.

Problem 7: Design a single Spark program to perform an ELT process with complex user-defined transformations, data optimization, and potential performance tuning.

Problem 8: Generate a PySpark code to mask the first 12 digits of a 16-digit credit card number and display only the last 4 digits.(CreditCardMasking.py)

Problem 9: Develop a performant PySpark data pipeline that reads data, applies a user-defined transformation on a specific column. (SentimentScore.py)

Problem 10: Develop Apache Spark application to analyze and prepare flight data for further exploration. (ProcessFlights.py)

Problem 11: Develop a PySpark script (filename: FlattenComplexJson.py) to parse deeply nested JSON data (6 levels), flatten it, and perform user-defined transformations.

Problem 11: Analyze customer purchase data to find total purchases per customer and top 10 revenue-generating products. (CustomerPurchases.py)

Problem 12: Write a pyspark code to concatenate two dataframes having  sligh different schemas. (ConcatenateDataFrames.py)
